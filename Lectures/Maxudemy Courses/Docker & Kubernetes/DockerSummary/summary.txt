2)Docker Images & Containers
    1)docker config file - see Dockerfile of code1 of section 2
    2)docker image
    3)docker container
    4)layer based architecture of image -
        images are read only
        optimizations of image
        conatiner is just one more layer over image
        when we pus a image on dockerHub, if our image is based on node, only our code is pushed. node part is taken from dockerHub
    5)container attached/detached mode
    6)docker logs
    6)interactiveMode - -i,-t and -it
    7)deleting images and conatiner -
        docker rm container1 container2
        docker prune
    8)copying files into and out from container.
        docker cp

    9)images tags, container names

    10)sharing images - 
        docker hub -
            renaming image (for pushing name needs to be in a particular format -  docker push repositoryName/imageName:imageTag)
            creating repository on dockerHub
            pushing your image
            pulling your image
        private registry
            will be covered later

3)Managing Data & Working with Volumes
   1)container data is retained when we stop container, it is deleted only when we remove container.
   2)solution - volume, slide 3
   3)Volumes -
        named  -
            specified while when running container (cannot be specified in Dockerfile as it is specific to container)
            survives container removal
        anonymous -
            mentioned in Dockerfile
            deleted when container is removed (if container is started with --rm flag)
            when container is created, it is recreated (even if last volume is not deleted)
   3)2 types of externalStorage - 
        volumes - dev is not aware of location on local system 
        Bind Mounts - 
            dev is aware of position on local system
            specified while creating container(cannot be specified in Dockerfile as it is specific to container)

    4)problem we faced while using mount -
        node_module folder was overwritten with bind mount.
        so we used anonymous volumes to sync nodu_modules folder and named volume to sync rest of code.
        this is use of anonymous volume.

        so we used all 3 types of storage here - code2
        bind mounts cannot be deleted via docker command.
        see side 7 for summary.

    6)readonly volumes 
        -v "pathOrName":"dockerPath":ro
        also we saw how to make one folder writable also by using anonymous volumes
    7).dockerignore
    8)arguments and env variables -
        env variables - code3
        arguments - code4


4)Networking:(Cross-)Container Communication
    a)see figure 1 , this is what we intend to do
    2)type 1 and type 2 are allowed by default.
        for type2 we see slide instead of local host we need a different string.
    3)connecting 2 docker containers -
        a)By using IP address
        b)by using docker network
    4)docker network driver
    5)connection via local system -
        mongodb container exposed port to local
        node server connects that port using - host.docker.internal.node also exposes a port to local
        react connects to node using localhost
    6)connection via network -
        1)run mongodb in container.
        2)run nodejs container and then connect to mongodb using container name. expose a port to local
        3)run frontend container,expose a port to local,connect with nodejs server by port exposed by nodejs server
        
    7)persisting data and auth -
        a)we persist data we used volume.
        b)for auth we set the env variables while running mongo db. and used that in string while connecting to mongo db. 

    8)other optimizations -
        a)live changes using bind mount
        b)passing mongo password through env variables
        c)using dockerignore fle to avid copying node_modules.

    9)limitations -
        a)long docker commands
        b_dev only setup


5)DockerCompose:Elegant MultiContainer Orchestration
    a)created a docker-compose.yaml.
    b)things that can be mentioned in docker-compose file -
        version
        service(container)
            image
            build 
                (path of Dockerfile that can be used to build image 
                    or 
                context, docker file name, arguments value)
            container_name
            volumes
            env variable/enVFile
            container name
            networks - in addition to default network
            ports
            stdin_open
            tty (both this and above for -it flag)
            depends_on - whether this container depends upon another container
        volumes section(for named volumes used in any service)

6)Utility Containers
    a)idea is that we want to setup projects without installing any tools on local machine.
    b)we can run commands inside docker container using "docker exec" command.
    c)we use bind mount to sync our local path with container path, run commands inside docker,
        get result back in our filesystem.
    d)ways to run commands -
        a)run commands inside running container by using "docker exec".
        b)while starting container we run our own command instead of default command of container -
            docker run -it containerName customCommand

        here we used second option see code1,code2. also we had a look at entryPoint Option. command we give while running
        container will be appended to entrypoint specified in Dockerfile.
    e)using docker-compose, here we ran commands inside containers started by docker-compose.
        docker compose run serviceName command
        see code3
    
7)A More Complex Setup
    a)Required Laravel setup - 
        figure 1 - we will have laravel code inside our system(in center image in figure), this will be exposed to PHP interpreter container.That is a container which has PHP installed inside of it.
        And that's a container which will have access to our source code so that it can interpret this source code and generate a response for incoming requests.

        incoming request are handled by nginx server, which then triggers PHP interpreter which runs our php code, for those requests.php container
        generates response for incoming requests and sends backs to client who requested it.For data base we have separate container. all these are
        application containers.we can say that PHP container, is in the end used by nginx to funnel individual files through it.

        For laravel application, we also need 3 kinds of utilities, so we have 3 utility containers also.
            a)composer - Composer is basically to PHP what NPM is to Node.It's a package manager which we can use to install third party packages and
                we will use Composer to create Laravel application and also Laravel will use Composer to install dependencies, which it needs.
            b)laravel Artisan - In addition Laravel ships with its own tool called Laravel Artisian.Now this is a command which we for example use
                to run migrations against our database and write initial starting data to the database.And we use it for a couple of other things as well.

            c)npm- Laravel uses it for some of its front end logic.So if in your views, which are returned by Laravel you need some Java script code, 
                for example.

    b)steps for setup -
        we setup 3 app containers in docker-compose.yaml file.
        see notes in docker-compose.yaml and corrosponding dockerfiles,
        then we setup a utility container - composer.
        first we run this utility container to generate laravel project. see first command in comamndsUsedInThisSection.txt.
        this creates sample project in src folder.
        now we change the DB connections settings in laravel project -
            go to .env file in source.
            change these things - DB username, password,host.
            make changes in file - resources->views -welcome
            go to localhost:8000, to see your changes live.

    c)setting up last 2 utility containers -
        then we setup 2 utility containers. dere we use option to mention some configs(entryPoint) in docker-compose file , instead of dockerFile,
        this is purely optional. Max prefer to have dockerFile.also dere are some configs like copy and run that we can only mention in
        DockerFile.

        while containing artisan utility container,we used dockerFile that we have for php container, but we gave it a EnrtyPoint.
        then we used artisan to do data base migration.
    d)Then we discussed about having configs in DockerFile vs docker-compose.
        we can have simpler configs in docker-compose file - EntryPoint and WorkingDir
        we cannot have complex instructions like RUN and COPY in docker.

    e)then we discussed that bind mount is great for development. but in production we do not need that.in prod we need to copy the snapshot
    for that we have code2.In folder 2 we have copied file into the containers, because in prod we do not want to change code
    and we want snapshot only. changes made -
        a)added a dockerFile of nginx because we want to copy file into that.
        b)then we saw importance of context in generating image.
        c)then we copied files into php container also. dere we got a error about read/write permission, so we we gave
            read/write access to user created by image.

        
